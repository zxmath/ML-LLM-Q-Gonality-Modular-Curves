[info]
#local_path = "data"
local_path = '/Users/xiaokangwang/Documents/PycharmProjects/MLmath_dataset'

train_set = "q_gonality_same_train.csv"
val_set = "q_gonality_same_val.csv"
test_set = "q_gonality_same_test.csv"
diff_set = "q_gonality_diff.csv"


#data_set = "combined_data_3.h5"
data_set = "combined_data_7.h5"



# List some features and targets for training and testing 


numerical_features = ["level", "genus", "rank", "cusps", "rational_cusps", "log_conductor", "coarse_class_num", "coarse_level"]
catorigical_features = ["pointless", "contains_negative_one", "level_is_squarefree"]
list_features = ['canonical_conjugator', 'conductor']
target = "q_gonality"
#target = 'genus'

saved_model_path = "saved_models"
# param
[params_xgb]

objective = 'reg:squarederror'
max_depth = 10
learning_rate = 0.02
n_estimators = 600
subsample = 0.6
colsample_bytree = 0.8
random_state = 42
device = 'gpu'
# tree_method = 'gpu_hist'
# predictor = 'gpu_predictor'
[params_lgb]

[FFN]

nn_data_path = "data\\Cross-Validation-Data"
nn_path = 'models\\NN_model'
nn_result_path = 'results\\NN-results'

batch_size = 32
learning_rate = 0.0001
hidden_sizes =  [128, 32]
optimizer = 'Adam'
criterion = "MSELoss" # when use this hyperparam,need to translate to nn.MSELoss()
num_epochs = 2000
activation_function = "LeakyReLU" #name of function
negative_slope = 0.01 # willu use nn.LeakyReLU(negative_slope = 0.01)

[LLM]
max_iter = 100

prompt_name = 'feature_extraction.txt'

[FT_Transformer]
numerical_features = ["level", "genus", "rank", "cusps", "rational_cusps", "log_conductor", "coarse_class_num", "coarse_level"]
catorigical_features = ["pointless", "contains_negative_one", "level_is_squarefree"]
list_features = ['canonical_conjugator', 'conductor']
target = "q_gonality"

# Model parameters
d_model = 128
n_layers = 4
activation = "gelu"
dropout = 0.1
nhead = 8
dim_feedforward = 512

# Training parameters
epochs = 270
learning_rate = 5e-4
weight_decay = 1e-4
patience = 50
batch_size = 64

# Categorical cardinalities (you may need to adjust these based on your data)
cat_cardinalities = {pointless = 2, contains_negative_one = 2, level_is_squarefree = 2}
# List cardinalities (adjust based on your data)
list_cardinalities = {canonical_conjugator = 1000, conductor = 1000}




